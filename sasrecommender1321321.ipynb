{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from split_data import split_seq_data\n",
    "from load_seq_data import load_train_data\n",
    "from sasrec import  SASRec"
   ],
   "id": "4a017fb066c8bae0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:37.332025Z",
     "start_time": "2024-12-14T17:56:37.316401Z"
    }
   },
   "cell_type": "code",
   "source": "file_path = 'D:/PyCharm/algorithm/xunlianxingmu/ml-1m/ratings.dat'",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:39.965175Z",
     "start_time": "2024-12-14T17:56:38.091392Z"
    }
   },
   "cell_type": "code",
   "source": "train_path, val_path, test_path, meta_path = split_seq_data(file_path=file_path)",
   "id": "c3d6b36ca20850a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines: 100%|██████████| 1000209/1000209 [00:01<00:00, 723697.17it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:39.995760Z",
     "start_time": "2024-12-14T17:56:39.965769Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_path)",
   "id": "6f8246a5de4fbb39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/PyCharm/algorithm/xunlianxingmu/ml-1m\\games_seq_train.txt\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:40.509654Z",
     "start_time": "2024-12-14T17:56:40.494031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假设你已经有了 meta_path 的路径\n",
    "with open(meta_path, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    print(\"Meta file content:\")\n",
    "    print(content)"
   ],
   "id": "a3b042d815997d83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta file content:\n",
      "6040\t3706\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:41.159254Z",
     "start_time": "2024-12-14T17:56:41.143630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # 调用 load_data 函数并处理返回的数据\n",
    "# file_path = file_path  # 替换为实际文件路径\n",
    "# neg_num = 4  # 每个正样本生成4个负样本\n",
    "# max_item_num = 3706  # 假设最大物品ID为3706（根据实际情况调整）\n",
    "# \n",
    "# loaded_data = load_data(file_path, neg_num, max_item_num)\n",
    "# \n",
    "# # 打印部分数据以验证\n",
    "# print(\"Sample data:\")\n",
    "# for i in range(min(5, len(loaded_data['user']))):  # 打印前五个样本或所有样本（如果少于5个）\n",
    "#     print(f\"User: {loaded_data['user'][i]}, Pos Item: {loaded_data['pos_item'][i]}, Neg Items: {loaded_data['neg_item'][i]}\")"
   ],
   "id": "641c86538598cb7c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:42.101660Z",
     "start_time": "2024-12-14T17:56:41.818875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用函数加载训练集数据\n",
    "train_path = train_path # 训练集文件路径\n",
    "max_item_num = 3706  # 假设最大物品ID为3706（根据实际情况调整）\n",
    "seq_len = 50  # 序列长度\n",
    "neg_num = 4   # 每个正样本生成4个负样本\n",
    "\n",
    "# 加载训练数据\n",
    "train_data = load_train_data(train_path, seq_len=seq_len, neg_num=neg_num, max_item_num=max_item_num, contain_user=True)\n",
    "\n",
    "# 打印部分数据以检查是否正确加载\n",
    "if train_data:\n",
    "    print(\"Train data example:\", train_data[0])\n",
    "else:\n",
    "    print(\"No train data loaded.\")"
   ],
   "id": "d4b9c80331296f99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data example: {'click_seq': [135, 130, 21, 172, 76, 117, 139, 98, 49, 133, 152, 63, 79, 114, 145, 149, 157, 91, 111, 146, 151, 156, 121, 167, 94, 118, 59, 123, 66, 120, 126, 95, 158, 161, 70, 75, 84, 119, 147, 155, 108, 138, 61, 99, 92, 127, 164, 74, 80, 131], 'pos_item': 67, 'neg_items': [2576, 209, 2750, 3182], 'user_id': 2}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:43.162930Z",
     "start_time": "2024-12-14T17:56:42.555757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_path = val_path\n",
    "test_path = test_path\n",
    "val_data = load_train_data(val_path, seq_len=seq_len, neg_num=neg_num, max_item_num=max_item_num, contain_user=True)\n",
    "test_data = load_train_data(test_path, seq_len=seq_len, neg_num=neg_num, max_item_num=max_item_num, contain_user=True)"
   ],
   "id": "e0c34739f042c6fe",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:43.761131Z",
     "start_time": "2024-12-14T17:56:43.589081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 test_data 是一个包含字典的列表\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "# 查看前几行\n",
    "print(df_test.head())"
   ],
   "id": "df3bdd6ca437e27f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           click_seq  pos_item  \\\n",
      "0  [32, 23, 28, 38, 25, 37, 4, 8, 48, 1, 22, 45, ...        33   \n",
      "1  [130, 21, 172, 76, 117, 139, 98, 49, 133, 152,...        73   \n",
      "2  [344, 40, 196, 28, 325, 121, 314, 239, 253, 30...        19   \n",
      "3  [387, 392, 420, 424, 400, 89, 105, 135, 423, 4...       154   \n",
      "4  [491, 54, 28, 60, 439, 32, 455, 323, 443, 446,...        41   \n",
      "\n",
      "                  neg_items  user_id  \n",
      "0  [2440, 1080, 1732, 1805]        1  \n",
      "1    [250, 3477, 606, 1046]        2  \n",
      "2   [1323, 699, 2793, 1182]        5  \n",
      "3  [3576, 1888, 2693, 1941]        6  \n",
      "4   [3536, 2842, 2211, 756]        8  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:44.391476Z",
     "start_time": "2024-12-14T17:56:44.360227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 假设 max_user_num 和 max_item_num 已经通过某些方式计算得到\n",
    "max_user_num = 10000  # 示例最大用户ID\n",
    "max_item_num = 3706   # 示例最大物品ID\n",
    "\n",
    "# 直接定义模型参数\n",
    "model_params = {\n",
    "    'item_num': 3706 + 1,          # 物品数量加1，以适应从1开始的索引\n",
    "    'embed_dim': 64,               # 嵌入维度\n",
    "    'seq_len': 50,                 # 序列长度，你可以根据数据集调整这个值\n",
    "    'blocks': 2,                   # Transformer blocks的数量\n",
    "    'num_heads': 1,                # 注意力头的数量\n",
    "    'ffn_hidden_unit': 128,        # FFN隐藏单元的数量\n",
    "    'dnn_dropout': 0.2,            # Dropout率\n",
    "    'layer_norm_eps': 1e-6,        # Layer normalization 的小浮点数，避免除零\n",
    "    'use_l2norm': False,           # 是否对用户和物品嵌入进行L2归一化\n",
    "    'loss_name': \"binary_cross_entropy_loss\",  # 默认损失函数名\n",
    "    'gamma': 0.5,                  # 如果选择 hinge_loss 作为损失函数，则可以指定 margin\n",
    "    'embed_reg': 0.,               # Embedding 正则化系数\n",
    "    'seed': 42                     # 随机种子\n",
    "}\n",
    "\n",
    "# 打印配置\n",
    "print(\"Model parameters:\", model_params)\n",
    "\n"
   ],
   "id": "4f72f30d64541c40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: {'item_num': 3707, 'embed_dim': 64, 'seq_len': 50, 'blocks': 2, 'num_heads': 1, 'ffn_hidden_unit': 128, 'dnn_dropout': 0.2, 'layer_norm_eps': 1e-06, 'use_l2norm': False, 'loss_name': 'binary_cross_entropy_loss', 'gamma': 0.5, 'embed_reg': 0.0, 'seed': 42}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建模型实例",
   "id": "647e14b95154f690"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:46.272932Z",
     "start_time": "2024-12-14T17:56:46.219419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建 SASRec 模型实例\n",
    "sasrec_model = SASRec(**model_params)\n",
    "# 设置优化器的学习率\n",
    "learning_rate = 0.001  # 默认学习率\n",
    "# 编译模型\n",
    "sasrec_model.compile(optimizer=Adam(learning_rate=learning_rate))\n"
   ],
   "id": "29e0eaf349c3fba8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:47.430861Z",
     "start_time": "2024-12-14T17:56:47.104789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 打印模型结构\n",
    "sasrec_model.summary()"
   ],
   "id": "32f2b816c3967d81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           multiple             237248      input_1[0][0]                    \n",
      "                                                                 tf.reshape[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.not_equal (TFOpLambda)  (None, 50)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 50, 64)       0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 50)           0           tf.math.not_equal[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 64)       0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 50, 1)        0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 50, 64)       0           dropout[0][0]                    \n",
      "                                                                 tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, 50, 64)       29312       tf.math.multiply[0][0]           \n",
      "                                                                 tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 50, 64)       0           transformer_encoder[0][0]        \n",
      "                                                                 tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_1 (Transfor (None, 50, 64)       29312       tf.math.multiply_1[0][0]         \n",
      "                                                                 tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None,)              0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 50, 64)       0           transformer_encoder_1[0][0]      \n",
      "                                                                 tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.slice (TFOpLambda)           (None, 1, 64)        0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_1 (TFOpLambda)   (None, 1, 64)        0           embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 1, 64)        0           tf.slice[0][0]                   \n",
      "                                                                 tf.expand_dims_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 1, 64)        0           tf.slice[0][0]                   \n",
      "                                                                 embedding[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 1)            0           tf.math.multiply_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 1)            0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 2)            0           tf.math.reduce_sum[0][0]         \n",
      "                                                                 tf.math.reduce_sum_1[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 295,872\n",
      "Trainable params: 295,872\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:48.140613Z",
     "start_time": "2024-12-14T17:56:47.874950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from tensorflow.keras.optimizers import Adam  # 导入Adam优化器\n",
    "\n",
    "# 假设 eval_pos_neg 和 SASRec 模型定义在其他文件中\n",
    "from evaluate_model import  Evaluate_model # 自定义评估函数\n",
    "from sasrec import SASRec  # 推荐系统模型\n"
   ],
   "id": "7978351559e22304",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用自定义评估函数进行训练和评估",
   "id": "169301335aafdda1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:56:49.401070Z",
     "start_time": "2024-12-14T17:56:49.322128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#转换数据格式\n",
    "from data_change import prepare_for_keras\n",
    "# 定义序列长度和负样本数量\n",
    "seq_len = 50  # 根据实际情况调整\n",
    "neg_num = 4  # 每个正样本生成4个负样本\n",
    "\n",
    "# 准备训练、验证和测试数据\n",
    "train_data_prepared = prepare_for_keras(train_data, seq_len, neg_num)\n",
    "val_data_prepared = prepare_for_keras(val_data, seq_len, neg_num)\n",
    "test_data_prepared = prepare_for_keras(test_data, seq_len, neg_num)\n",
    "\n",
    "# 现在你可以使用准备好的数据进行训练和评估"
   ],
   "id": "b8bd21ee77d75ca8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:57:42.717804Z",
     "start_time": "2024-12-14T17:57:42.702181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检查数据结构\n",
    "print(\"Train data example:\", train_data[0] if train_data else \"No data\")\n",
    "print(\"Validation data example:\", val_data[0] if val_data else \"No data\")\n",
    "print(\"Test data example:\", test_data[0] if test_data else \"No data\")"
   ],
   "id": "f1bbc82bc5584163",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data example: {'click_seq': [135, 130, 21, 172, 76, 117, 139, 98, 49, 133, 152, 63, 79, 114, 145, 149, 157, 91, 111, 146, 151, 156, 121, 167, 94, 118, 59, 123, 66, 120, 126, 95, 158, 161, 70, 75, 84, 119, 147, 155, 108, 138, 61, 99, 92, 127, 164, 74, 80, 131], 'pos_item': 67, 'neg_items': [2576, 209, 2750, 3182], 'user_id': 2}\n",
      "Validation data example: {'click_seq': [135, 130, 21, 172, 76, 117, 139, 98, 49, 133, 152, 63, 79, 114, 145, 149, 157, 91, 111, 146, 151, 156, 121, 167, 94, 118, 59, 123, 66, 120, 126, 95, 158, 161, 70, 75, 84, 119, 147, 155, 108, 138, 61, 99, 92, 127, 164, 74, 80, 131], 'pos_item': 67, 'neg_items': [2816, 736, 1587, 3038], 'user_id': 2}\n",
      "Test data example: {'click_seq': [32, 23, 28, 38, 25, 37, 4, 8, 48, 1, 22, 45, 10, 52, 44, 42, 49, 19, 12, 15, 43, 18, 40, 46, 27, 3, 7, 20, 39, 53, 2, 14, 50, 51, 16, 21, 47, 6, 9, 13, 29, 24, 11, 17, 30, 34, 41, 5, 31, 36], 'pos_item': 33, 'neg_items': [2440, 1080, 1732, 1805], 'user_id': 1}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-14T17:59:17.163867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 假设 SASRec 类和其他依赖项已经定义好了，并且你已经有了 train_data, val_data, test_data\n",
    "\n",
    "# 定义训练和评估的超参数\n",
    "epochs = 5  # 训练轮数\n",
    "batch_size = 128  # 批量大小\n",
    "k = 10  # 评估时考虑的前K个推荐项目\n",
    "seq_len = 50  # 序列长度（根据实际情况调整）\n",
    "neg_num = 4  # 每个正样本生成4个负样本\n",
    "\n",
    "# 初始化模型并编译\n",
    "item_num = 3706  # 根据实际情况调整最大物品ID\n",
    "embed_dim = 50  # 嵌入维度\n",
    "model_params = {\n",
    "    'item_num': item_num,\n",
    "    'embed_dim': embed_dim,\n",
    "    'seq_len': seq_len,\n",
    "    'blocks': 2,\n",
    "    'num_heads': 1,\n",
    "    'ffn_hidden_unit': 64,\n",
    "    'dnn_dropout': 0.2,\n",
    "    'layer_norm_eps': 1e-6,\n",
    "    'use_l2norm': True,\n",
    "    'loss_name': \"binary_cross_entropy_loss\",\n",
    "    'gamma': 0.5,\n",
    "    'embed_reg': 0.,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "model = SASRec(**model_params)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')\n",
    "\n",
    "# 创建 TensorFlow 数据集以提高效率\n",
    "def create_tf_dataset(data, batch_size):\n",
    "    click_seqs = np.array([entry['click_seq'][-seq_len:] for entry in data])\n",
    "    pos_items = np.array([entry['pos_item'] for entry in data])\n",
    "    neg_items = np.array([entry['neg_items'][:neg_num] for entry in data])\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'click_seq': click_seqs,\n",
    "            'pos_item': pos_items,\n",
    "            'neg_item': neg_items\n",
    "        },\n",
    "        tf.ones((len(click_seqs),))  # 假设正样本标签为1\n",
    "    ))\n",
    "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = create_tf_dataset(train_data, batch_size)\n",
    "val_dataset = create_tf_dataset(val_data, batch_size)\n",
    "\n",
    "# 开始训练和评估\n",
    "for epoch in range(1, epochs + 1):\n",
    "    t1 = time.time()\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=1,\n",
    "        validation_data=val_dataset,\n",
    "        verbose=1  # 设置为1可以在每个epoch后输出进度条\n",
    "    )\n",
    "    t2 = time.time()\n",
    "\n",
    "    # 假设 Evaluate_model 函数已经定义好，并能返回评估指标字典\n",
    "    eval_dict = Evaluate_model(model, test_data, k=k)\n",
    "    print('Iteration %d Fit [%.1f s], Evaluate [%.1f s]: HR = %.4f, MRR = %.4f, NDCG = %.4f' %\n",
    "          (epoch, t2 - t1, time.time() - t2, eval_dict['hr'], eval_dict['mrr'], eval_dict['ndcg']))\n",
    "\n",
    "# 如果需要保存模型\n",
    "# model.save('sasrec_model.h5')"
   ],
   "id": "b0aab4b083fc7229",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 4s 63ms/step - loss: 9.2387 - val_loss: 8.1855\n",
      "Iteration 1 Fit [3.6 s], Evaluate [89.2 s]: HR = 1.0000, MRR = 0.4479, NDCG = 1.0000\n",
      "33/33 [==============================] - 2s 56ms/step - loss: 7.4575 - val_loss: 6.5565\n",
      "Iteration 2 Fit [1.8 s], Evaluate [88.1 s]: HR = 1.0000, MRR = 0.4291, NDCG = 1.0000\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 5.9661 - val_loss: 5.5074\n",
      "Iteration 3 Fit [1.8 s], Evaluate [88.0 s]: HR = 1.0000, MRR = 0.4150, NDCG = 1.0000\n",
      "33/33 [==============================] - 2s 58ms/step - loss: 5.0978 - val_loss: 4.8941\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T16:28:50.927482Z",
     "start_time": "2024-12-14T16:28:50.793150Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "18f73212e04cf191",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['1\\t32 23 28 38 25 37 4 8 48 1 22 45 10 52 44 42 49 19 12 15 43 18 40 46 27 3 7 20 39 53 2 14 50 51 16 21 47 6 9 13 29 24 11 17 30 34 41 5 31 36 33\\t978300019 978300055 978300055 978300055 978300103 978300172 978300275 978300719 978300719 978300760 978300760 978300760 978301368 978301398 978301570 978301590 978301619 978301713 978301752 978301753 978301753 978301777 978301777 978301777 978301953 978301968 978302039 978302039 978302091 978302091 978302109 978302124 978302149 978302174 978302188 978302205 978302205 978302268 978302268 978302281 978824139 978824195 978824268 978824268 978824268 978824268 978824268 978824291 978824291 978824291 978824330']\n",
      "  1\\t32 23 28 38 25 37 4 8 48 1 22 45 10 52 44 42 49 19 12 15 43 18 40 46 27 3 7 20 39 53 2 14 50 51 16 21 47 6 9 13 29 24 11 17 30 34 41 5 31 36 33\\t978300019 978300055 978300055 978300055 978300103 978300172 978300275 978300719 978300719 978300760 978300760 978300760 978301368 978301398 978301570 978301590 978301619 978301713 978301752 978301753 978301753 978301777 978301777 978301777 978301953 978301968 978302039 978302039 978302091 978302091 978302109 978302124 978302149 978302174 978302188 978302205 978302205 978302268 978302268 978302281 978824139 978824195 978824268 978824268 978824268 978824268 978824268 978824291 978824291 978824291 978824330\n",
      "0  2\\t128 65 72 132 88 166 106 1 168 71 105 68 10...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "1  3\\t129 105 179 169 182 42 195 197 198 204 124 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "2  4\\t65 27 64 114 215 45 125 128 214 49 213 216 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "3  5\\t132 322 10 237 172 105 278 369 353 361 185 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "4  6\\t393 167 421 396 179 65 265 418 419 410 412 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f84ff6acdb414b1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
